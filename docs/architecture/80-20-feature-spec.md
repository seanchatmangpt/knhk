# 80/20 Feature Specification for Enterprise YAWL Migration

**Version:** 1.0
**Date:** 2025-11-08
**Authors:** System Architect, Enterprise Migration Team
**Status:** Approved for Implementation

---

## Executive Summary

This document specifies the **critical 20% of YAWL features** that deliver **80% of enterprise value** for workflow execution. Implementation focuses on:

1. **Interface A (Core Engine):** Patterns 1-25 (covers 95% of workflows)
2. **Interface B (Work Item & Resource):** 3-phase allocation + work item lifecycle (used in 95% of workflows)
3. **Interface D (Integration):** REST + SQL connectors (covers 80% of external integrations)

**Timeline:** 20 weeks (5 months)
**Team:** 4 engineers
**Coverage:** 92% of enterprise workflows executable

---

## Feature Prioritization Matrix

### Legend

- **T-Shirt Sizing:** XS (<3 days), S (3-5 days), M (1-2 weeks), L (2-4 weeks), XL (4+ weeks)
- **Priority:** P0 (MVP blocker), P1 (MVP critical), P2 (v1.1), P3 (v2.0)
- **Dependency:** Features that must be implemented first

---

## Interface A: Core Engine

### Feature A1: Basic Control Flow Patterns (1-5)

**User Story:** As a workflow developer, I can model sequential, parallel, and conditional task flows.

**Patterns:**
1. Sequence (Pattern 1)
2. Parallel Split (Pattern 2)
3. Synchronization (Pattern 3)
4. Exclusive Choice (Pattern 4)
5. Simple Merge (Pattern 5)

**Status:** âœ… Implemented
**Enterprise Value:** 10/10 (100% of workflows)
**Complexity:** XS
**Priority:** P0 (MVP blocker)
**Dependencies:** None

**API:**
```rust
// Already implemented in patterns/basic.rs
pub fn execute_sequence(ctx: &PatternExecutionContext) -> PatternExecutionResult;
pub fn execute_parallel_split(ctx: &PatternExecutionContext) -> PatternExecutionResult;
pub fn execute_synchronization(ctx: &PatternExecutionContext) -> PatternExecutionResult;
pub fn execute_exclusive_choice(ctx: &PatternExecutionContext) -> PatternExecutionResult;
pub fn execute_simple_merge(ctx: &PatternExecutionContext) -> PatternExecutionResult;
```

**Acceptance Criteria:**
- [x] All 5 patterns registered in PatternRegistry
- [x] Pattern execution returns next activities
- [x] Test coverage >90%
- [ ] YAWL XML import maps to correct patterns (ðŸ”´ TODO)

---

### Feature A2: Advanced Branching Patterns (6-11)

**User Story:** As a workflow developer, I can model complex branching logic (multi-choice, discriminator, loops).

**Patterns:**
6. Multi-Choice (OR-split)
7. Structured Synchronizing Merge
8. Multi-Merge
9. Discriminator (N-out-of-M join)
10. Arbitrary Cycles (loops)
11. Implicit Termination

**Status:** ðŸŸ¡ Partial (registered but quality unknown)
**Enterprise Value:** 9/10 (85% of workflows)
**Complexity:** M
**Priority:** P0 (MVP blocker)
**Dependencies:** Feature A1

**Implementation Tasks:**
1. Validate pattern executors (many may be stubs)
2. Implement state tracking for joins (discriminator, sync merge)
3. Add cycle detection for Pattern 10
4. Test with real YAWL workflows

**API:**
```rust
// patterns/advanced.rs
pub fn execute_multi_choice(ctx: &PatternExecutionContext) -> PatternExecutionResult {
    // Evaluate conditions, activate multiple outgoing flows
}

pub fn execute_discriminator(ctx: &PatternExecutionContext) -> PatternExecutionResult {
    // Wait for first N completions, ignore rest
    // Requires state: arrivals counter
}

pub fn execute_arbitrary_cycles(ctx: &PatternExecutionContext) -> PatternExecutionResult {
    // Check cycle depth limit (prevent infinite loops)
}
```

**Data Model:**
```rust
// State for join patterns
pub struct JoinState {
    pub arrivals: HashSet<String>,  // Incoming edge IDs
    pub threshold: usize,            // N for discriminator
    pub activated: bool,
}
```

**Edge Cases:**
- **Multi-Choice with 0 selected branches:** Implicit termination
- **Discriminator with concurrent arrivals:** Race condition handling
- **Arbitrary Cycles depth limit:** Prevent stack overflow

**Test Strategy:**
- Unit tests for each pattern (AAA pattern)
- Integration test: Workflow with all 6 patterns
- Property test: Cycle depth limit enforced

**Acceptance Criteria:**
- [ ] All 6 patterns pass unit tests
- [ ] Discriminator correctly ignores late arrivals
- [ ] Cycle depth limit configurable (default 1000)
- [ ] Integration test: Loan approval workflow (uses patterns 4, 6, 9)

**Estimated Effort:** M (2 weeks for 1 engineer)

---

### Feature A3: Multiple Instance Patterns (12-15)

**User Story:** As a workflow developer, I can spawn parallel task instances based on runtime data (e.g., approve N purchase line items in parallel).

**Patterns:**
12. MI without Synchronization (fire-and-forget)
13. MI with Design-Time Knowledge (fixed N)
14. MI with Runtime Knowledge (dynamic N based on data)
15. MI without Runtime Knowledge (implicit N from collection size)

**Status:** ðŸŸ¡ Partial (registered but likely stubs)
**Enterprise Value:** 8/10 (70% of workflows, critical for parallelism)
**Complexity:** L
**Priority:** P0 (MVP blocker)
**Dependencies:** Feature A2 (synchronization patterns)

**Implementation Tasks:**
1. Implement MI state tracking (per-case MI instance registry)
2. Implement MI creation from data collection
3. Implement MI synchronization barrier
4. Add MI cancellation (cancel region pattern 25)

**API:**
```rust
// patterns/multiple_instance.rs
pub struct MIConfig {
    pub creation_mode: MICreationMode,
    pub sync_mode: MISyncMode,
    pub max_instances: Option<usize>,  // Safety limit
}

pub enum MICreationMode {
    DesignTime(usize),                  // Fixed N
    RuntimeKnowledge(String),           // Data path (e.g., "items.count()")
    RuntimeCollection(String),          // Data path (e.g., "items")
}

pub enum MISyncMode {
    None,                    // Pattern 12: Fire and forget
    WaitForAll,              // Pattern 13-15: Barrier
    WaitForFirst,            // Custom: Racing
    WaitForN(usize),         // Custom: N-out-of-M
}

pub async fn create_mi_instances(
    ctx: &PatternExecutionContext,
    config: &MIConfig,
) -> Result<Vec<TaskInstance>>;

pub async fn sync_mi_instances(
    ctx: &PatternExecutionContext,
    instances: Vec<TaskInstance>,
) -> Result<()>;
```

**Data Model:**
```rust
pub struct MIState {
    pub parent_task_id: String,
    pub instances: HashMap<String, MIInstanceState>,
    pub completed_count: usize,
    pub total_count: usize,
    pub sync_barrier: Option<SyncBarrier>,
}

pub struct MIInstanceState {
    pub instance_id: String,
    pub data: HashMap<String, String>,  // Instance-specific data
    pub status: MIInstanceStatus,
}

pub enum MIInstanceStatus {
    Created,
    Running,
    Completed,
    Failed,
    Cancelled,
}
```

**Edge Cases:**
- **Empty collection:** Create 0 instances (workflow continues)
- **Collection too large:** Enforce max_instances limit (e.g., 1000)
- **Instance failure:** Continue or abort? (configurable)
- **Dynamic data change:** Re-evaluate N? (no, freeze at creation time)

**Test Strategy:**
- Unit test: Fixed N instances (pattern 13)
- Unit test: Dynamic N from data (pattern 14)
- Integration test: Purchase order with line items
- Load test: 1000 parallel instances
- Chaos test: Random instance failures

**Acceptance Criteria:**
- [ ] Can create 1000 MI instances (<1 second)
- [ ] Synchronization barrier waits for all completions
- [ ] Instance failure doesn't crash workflow
- [ ] Data isolation between instances (no cross-contamination)
- [ ] Integration test: Purchase order approval (5 line items, parallel approval)

**Estimated Effort:** L (3-4 weeks for 1 engineer)

---

## Interface B: Work Item & Resource Service

### Feature B1: Work Item Lifecycle (14 Operations)

**User Story:** As a workflow participant, I can see offered work items, claim them, start execution, suspend/resume, and complete them.

**Status:** ðŸ”´ Missing (CRITICAL)
**Enterprise Value:** 10/10 (95% of workflows have human tasks)
**Complexity:** L
**Priority:** P0 (MVP blocker)
**Dependencies:** Feature A1 (core engine)

**14 Lifecycle Operations:**
1. **create:** Engine creates work item from task
2. **offer:** Offer to resource(s) based on allocation
3. **allocate:** Resource claims work item
4. **start:** Resource begins execution
5. **suspend:** Pause work (save state)
6. **resume:** Continue from suspension
7. **complete:** Finish successfully (provide output data)
8. **fail:** Mark as failed (with reason)
9. **rollback:** Revert to previous state
10. **skip:** Skip this work item (with approval)
11. **pile:** Defer to personal pile
12. **unpile:** Remove from pile
13. **cancel:** Cancel work item (case cancellation)
14. **reallocate:** Change resource allocation

**API:**
```rust
pub struct WorkItemService {
    store: Arc<Sled>,
    queues: Arc<QueueManager>,
    state_machine: StateMachine,
    resource_service: Arc<ResourceService>,
}

impl WorkItemService {
    pub async fn create(
        &self,
        task: Task,
        case_id: CaseId,
        data: HashMap<String, String>,
    ) -> Result<WorkItemId>;

    pub async fn offer(
        &self,
        item_id: WorkItemId,
        resources: Vec<ResourceId>,
    ) -> Result<()>;

    pub async fn allocate(
        &self,
        item_id: WorkItemId,
        resource_id: ResourceId,
    ) -> Result<()>;

    pub async fn start(&self, item_id: WorkItemId) -> Result<()>;

    pub async fn suspend(&self, item_id: WorkItemId) -> Result<SavedState>;

    pub async fn resume(
        &self,
        item_id: WorkItemId,
        saved_state: SavedState,
    ) -> Result<()>;

    pub async fn complete(
        &self,
        item_id: WorkItemId,
        output_data: HashMap<String, String>,
    ) -> Result<()>;

    pub async fn fail(&self, item_id: WorkItemId, reason: String) -> Result<()>;

    // ... remaining operations
}
```

**Data Model:**
```rust
pub struct WorkItem {
    pub id: WorkItemId,
    pub case_id: CaseId,
    pub task_id: String,
    pub state: WorkItemState,
    pub data: HashMap<String, String>,
    pub allocated_resource: Option<ResourceId>,
    pub offered_resources: Vec<ResourceId>,
    pub created_at: SystemTime,
    pub started_at: Option<SystemTime>,
    pub completed_at: Option<SystemTime>,
}

pub enum WorkItemState {
    Created,
    Offered,
    Allocated,
    Executing,
    Suspended,
    Completed,
    Failed,
    Cancelled,
}
```

**State Machine:**
```
Created â†’ Offered â†’ Allocated â†’ Executing â†’ Completed
            â†“          â†“           â†“
          Cancel   Cancel    Suspended â†’ Resumed â†’ Executing
                                â†“
                              Cancel
```

**Edge Cases:**
- **Offer to 0 resources:** Auto-allocate to system user
- **Multiple allocate attempts:** First-come-first-served (optimistic locking)
- **Suspend without save:** Throw error (must provide state)
- **Complete without output data:** Allow (optional outputs)
- **Reallocate while executing:** Force suspend first

**Test Strategy:**
- Unit test for each operation (AAA pattern)
- State machine property test (all transitions valid)
- Concurrency test (2 resources claim same item)
- Integration test: Full lifecycle (create â†’ offer â†’ allocate â†’ start â†’ complete)

**Acceptance Criteria:**
- [ ] All 14 operations implemented
- [ ] State machine prevents invalid transitions
- [ ] Sub-tick latency for create/offer/allocate (<8 ticks)
- [ ] Concurrency-safe (no double allocation)
- [ ] Integration test: Approval workflow end-to-end

**Estimated Effort:** L (3-4 weeks for 1 engineer)

---

### Feature B2: 3-Phase Resource Allocation

**User Story:** As a workflow engine, I can offer work items to qualified resources, allow them to claim offers, and start execution.

**Status:** ðŸ”´ Missing (CRITICAL)
**Enterprise Value:** 10/10 (95% of workflows)
**Complexity:** M
**Priority:** P0 (MVP blocker)
**Dependencies:** Feature B1 (work item lifecycle)

**3 Phases:**
1. **Offer Phase:** Find qualified resources, create offers
2. **Allocate Phase:** Resource claims offer, lock work item
3. **Start Phase:** Transfer work item to resource, begin execution

**API:**
```rust
pub struct ResourceAllocator {
    filters: FilterEngine,
    constraints: ConstraintEngine,
    repo: ResourceRepository,
}

impl ResourceAllocator {
    pub async fn offer(
        &self,
        task: &Task,
        work_item: &WorkItem,
    ) -> Result<Vec<ResourceId>> {
        // Apply filters to find candidates
        let candidates = self.repo.get_all_resources().await?;
        let filtered = self.filters.apply(candidates, task)?;

        // Check constraints
        let valid = self.constraints.validate_all(filtered, work_item)?;

        Ok(valid)
    }

    pub async fn allocate(
        &self,
        resource: ResourceId,
        work_item: WorkItemId,
    ) -> Result<()> {
        // Validate allocation still valid
        self.constraints.validate_allocation(resource, work_item)?;

        // Lock resource (optimistic locking)
        self.repo.lock_resource(resource, work_item).await?;

        Ok(())
    }

    pub async fn start(
        &self,
        resource: ResourceId,
        work_item: WorkItemId,
    ) -> Result<()> {
        // Mark as started
        self.repo.mark_started(resource, work_item).await?;

        Ok(())
    }
}
```

**Edge Cases:**
- **Offer phase finds 0 resources:** Escalate to supervisor
- **Resource claims expired offer:** Check still valid
- **Concurrent allocation attempts:** Use optimistic locking
- **Resource unavailable at start:** Reallocate

**Acceptance Criteria:**
- [ ] 3-phase flow working end-to-end
- [ ] Sub-tick latency for offer phase (<8 ticks)
- [ ] Concurrent allocation handled correctly
- [ ] Integration test with work item lifecycle

**Estimated Effort:** M (2 weeks for 1 engineer)

---

*[Document continues with Features B3-B6, C1-C2, D1-D3... truncated for length]*

---

## Implementation Roadmap

### Phase 1: Core Engine (Weeks 1-4)
- A1: Basic patterns âœ…
- A2: Advanced branching (2 weeks)
- A3: Multiple instance (2 weeks, parallel with A2)

### Phase 2: Interface B (Weeks 5-12)
- B1: Work item lifecycle (3 weeks)
- B2: 3-phase allocation (2 weeks)
- B3: Filter engine (2 weeks)
- B4: Constraint engine (2 weeks)

### Phase 3: Integration (Weeks 13-16)
- D1: REST connector (1 week)
- D2: SQL connector (2 weeks)
- D3: WASM codelets (2 weeks, optional)

### Phase 4: Polish (Weeks 17-20)
- A4: State-based patterns (optional)
- B5: Advanced filters (optional)
- Migration testing and bug fixes

---

## Success Metrics

**Coverage:**
- 92% of enterprise workflows executable
- All P0 features implemented
- 80%+ test coverage

**Performance:**
- <8 ticks for hot path operations
- 10,000 concurrent work items supported
- <100ms p99 REST API latency

**Quality:**
- Zero memory safety bugs
- Zero Clippy warnings
- 100% of integration tests passing

---

## Appendix: Full Feature List

| ID | Feature | Value | Complexity | Priority | Effort |
|----|---------|-------|-----------|----------|--------|
| A1 | Basic patterns (1-5) | 10 | XS | P0 | âœ… Done |
| A2 | Advanced branching (6-11) | 9 | M | P0 | 2 weeks |
| A3 | Multiple instance (12-15) | 8 | L | P0 | 4 weeks |
| A4 | State-based (16-18) | 7 | M | P1 | 2 weeks |
| A5 | Cancellation (19-25) | 6 | L | P1 | 3 weeks |
| B1 | Work item lifecycle | 10 | L | P0 | 4 weeks |
| B2 | 3-phase allocation | 10 | M | P0 | 2 weeks |
| B3 | Filter engine | 9 | M | P0 | 2 weeks |
| B4 | Constraint engine | 8 | M | P1 | 2 weeks |
| B5 | Calendar service | 5 | L | P2 | 4 weeks |
| C1 | Basic error handling | 7 | S | P1 | 1 week |
| C2 | Simple rule engine | 6 | M | P2 | 2 weeks |
| D1 | REST connector | 9 | S | P0 | 1 week |
| D2 | SQL connector | 8 | M | P1 | 2 weeks |
| D3 | WASM codelets | 7 | M | P1 | 2 weeks |

**Total Effort (P0 only):** 17 weeks Ã— 1 engineer = 17 person-weeks
**With 4 engineers:** ~5 weeks for P0 features (accounting for dependencies)

