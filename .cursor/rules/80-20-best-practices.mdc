---
description: KNHKS 80/20 Core Team Best Practices
globs:
  - "**/*.rs"
  - "**/*.c"
  - "**/*.h"
alwaysApply: true
---

# KNHKS Core Team Best Practices - 80/20 Production-Ready Code

## Core Principle: No Placeholders, Real Implementations

All code must be production-ready with proper error handling. Focus on critical path implementations that provide 80% of value.

**Key Principle**: "Never trust the text, only trust test results" - All implementations must be verifiable through tests and OTEL validation.

## Prohibited Patterns ❌

1. **Placeholders** - No "In production, this would..." comments
2. **TODOs** - No TODO comments except clearly documented future enhancements
3. **Unhandled errors** - No `unwrap()`, `expect()`, or panics in production code
4. **Stubs** - No functions that always succeed without implementation
5. **Simulated behavior** - Use real libraries when available (rdkafka, reqwest, etc.)
6. **Claims without verification** - Never claim code works without test/OTEL validation
7. **Defensive programming** - No validation checks in execution paths (hot path, executor, state). Validation happens at ingress only via guards.

## Required Patterns ✅

1. **Input validation at ingress** - Validate all inputs at ingress points via guards, enforce guard constraints (max_run_len ≤ 8)
2. **Test verification** - All code must be testable and tested (OTEL validation preferred)
3. **Execution paths assume pre-validated inputs** - Hot path, executor, state management assume inputs validated at ingress

## Performance Requirements

- Hot path operations: ≤8 ticks (Chatman Constant)
- Branchless operations for hot path (constant-time execution)

## Error Handling Requirements

- Never use `unwrap()` or `expect()` in production code paths
- Validate inputs at ingress: guards (`security/guards.rs`), admission gates (`services/admission.rs`)
- Execution paths assume pre-validated inputs: no defensive checks in hot path, executor, state

## Testing Requirements

- Test guard violations
- **OTEL validation is ultimate truth source** - verify with real spans/metrics
- Never trust claims without test/OTEL verification
- **Test behaviors, not implementation details** - Focus on what code does, not how

### Using chicago-tdd-tools

**Required**: Use `chicago-tdd-tools` macros and utilities for all Rust tests.

- **Test macros**: `chicago_test!`, `chicago_async_test!`, `chicago_fixture_test!`, `chicago_performance_test!` - enforce AAA pattern and reduce boilerplate
- **Assertion macros**: `assert_ok!`, `assert_err!`, `assert_within_tick_budget!`, `assert_guard_constraint!` - provide better error messages
- **Validation utilities**: Use OTEL validation, performance validation (RDTSC), guard constraint enforcement, Weaver live validation from `chicago-tdd-tools`

Example:
```rust
use chicago_tdd_tools::prelude::*;

chicago_performance_test!(test_hot_path, {
    // Arrange
    let input = create_test_input();
    
    // Act
    let (result, ticks) = measure_ticks(|| hot_path(&input));
    
    // Assert
    assert_within_tick_budget!(ticks, "Hot path operation");
    assert_ok!(&result);
});
```

## Guard Constraints

- max_run_len ≤ 8 (Chatman Constant)
- max_batch_size validation
- Schema validation (IRI format checking)
- Operation validation (H_hot set membership)

## Async/Sync Best Practices

### ❌ NEVER make trait methods async - breaks dyn compatibility
```rust
// ❌ Bad: Async trait methods break dyn compatibility
pub trait ServicePlugin: Send + Sync {
    async fn start(&self) -> Result<ServiceHandle>; // BREAKS dyn ServicePlugin!
}

// ✅ Good: Keep trait methods sync, use async in implementations
pub trait ServicePlugin: Send + Sync {
    fn start(&self) -> Result<ServiceHandle>; // dyn compatible
}
```

### ✅ Use async for I/O and long-running operations
- Never block async contexts with `std::thread::sleep` - use `tokio::time::sleep` instead

## Anti-False-Positive Rules - CRITICAL

### ❌ NEVER fake implementation with Ok(()) stubs
```rust
// ❌ Bad: Fake success without doing work
pub fn execute_test(&self) -> Result<()> {
    println!("Test executed successfully");  // LYING!
    Ok(())  // Returns success but did nothing
}

// ✅ Good: Honest about incomplete implementation
pub fn execute_test(&self) -> Result<()> {
    unimplemented!("execute_test: needs container execution, output capture, and result validation")
}

// ✅ Good: Actually implemented
pub fn execute_test(&self) -> Result<()> {
    let container = self.start_container()?;
    let output = container.exec(&self.command)?;
    self.validate_output(&output)?;
    Ok(())  // Now legitimately successful
}
```

### Rules for Production Code
1. If a method body is incomplete, it MUST call `unimplemented!("Feature X: what's missing")`
2. NEVER return `Ok(())` without actually doing the work described by the method name
3. NEVER print "success" when nothing happened
4. CLI commands that don't work MUST throw `unimplemented!()`, not pretend to succeed
5. Methods must either work end-to-end OR throw unimplemented
6. No middle ground - no "partial" implementations that lie about success

## Code Review Checklist

- [ ] All inputs validated at ingress (guards, admission gates)
- [ ] No defensive checks in execution paths (hot path, executor, state)
- [ ] No `unwrap()` or `panic!()` in production paths
- [ ] Real implementations, not placeholders
- [ ] Guard constraints enforced at ingress (max_run_len ≤ 8)
- [ ] Hot path operations are branchless/constant-time
- [ ] Performance constraints met (≤8 ticks for hot path)
- [ ] Code verified with tests/OTEL validation
- [ ] No fake implementations - incomplete features call `unimplemented!()`
- [ ] All traits are `dyn` compatible (no async trait methods)
- [ ] Tests verify behavior, not implementation details
- [ ] Use chicago-tdd-tools macros for tests (reduces boilerplate, enforces AAA pattern)
- [ ] Use chicago-tdd-tools validation utilities (OTEL, performance, guards, Weaver)

## Definition of Done - Core Team Standards

### Before any code is considered complete, ALL of these must be true:

1. **✅ Compilation**: Code compiles without errors or warnings
2. **✅ No unwrap()/expect()**: Zero usage of unwrap() or expect() in production code
3. **✅ Trait Compatibility**: All traits remain `dyn` compatible (no async trait methods)
4. **✅ Backward Compatibility**: No breaking changes without migration plan
5. **✅ All Tests Pass**: Every test in the codebase passes
6. **✅ No Linting Errors**: Zero linting errors or warnings
7. **✅ Proper Error Handling**: All functions use Result types with meaningful errors
8. **✅ Async/Sync Patterns**: Proper use of async for I/O, sync for computation
9. **✅ No False Positives**: No fake Ok(()) returns from incomplete implementations
10. **✅ Performance Compliance**: Hot path operations ≤8 ticks
11. **✅ OTEL Validation**: Behavior verified with real spans/metrics

### Validation Checklist:
- [ ] No `unwrap()` or `expect()` in production code
- [ ] All traits are `dyn` compatible
- [ ] No fake implementations - incomplete features call `unimplemented!()`
- [ ] Tests verify behavior, not implementation details
- [ ] Performance constraints met (≤8 ticks for hot path)
- [ ] Use chicago-tdd-tools macros for tests (reduces boilerplate, enforces AAA pattern)
- [ ] Use chicago-tdd-tools validation utilities (OTEL, performance, guards, Weaver)

### If ANY of these fail, the code is NOT ready for production.
