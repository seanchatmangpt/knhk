---
description: KNHKS 80/20 Core Team Best Practices
globs:
  - "**/*.rs"
  - "**/*.c"
  - "**/*.h"
alwaysApply: true
---

# KNHKS Core Team Best Practices - 80/20 Production-Ready Code

## Core Principle: No Placeholders, Real Implementations

All code must be production-ready with proper error handling. Focus on critical path implementations that provide 80% of value.

**Key Principle**: "Never trust the text, only trust test results" - All implementations must be verifiable through tests and OTEL validation.

## Prohibited Patterns ❌

1. **Placeholders** - No "In production, this would..." comments
2. **TODOs** - No TODO comments except clearly documented future enhancements
3. **Unhandled errors** - No `unwrap()`, `expect()`, or panics in production code
4. **Stubs** - No functions that always succeed without implementation
5. **Simulated behavior** - Use real libraries when available (rdkafka, reqwest, etc.)
6. **Claims without verification** - Never claim code works without test/OTEL validation

## Required Patterns ✅

1. **Real library integrations** - Use actual dependencies when available
2. **Error handling** - `Result<T, E>` for all fallible operations (Rust)
3. **Feature gating** - `#[cfg(feature = "...")]` for optional dependencies
4. **Input validation** - Validate all inputs, enforce guard constraints (max_run_len ≤ 8)
5. **Test verification** - All code must be testable and tested (OTEL validation preferred)

## Performance Requirements

- Hot path operations: ≤8 ticks (Chatman Constant)
- Zero-copy when possible (references over clones)
- Branchless operations for hot path (constant-time execution)
- Focus on 20% of features that provide 80% of value

## Error Handling Requirements

- Use `Result<T, E>` for all fallible operations (Rust)
- Return error codes: `int process(...)` with `-1` on error (C)
- Validate inputs early: check NULL pointers, bounds
- Never use `unwrap()` or `expect()` in production code paths
- Provide context in error messages

## Testing Requirements

- Test all public APIs
- Test error paths and guard violations
- Test critical paths (aim for 80%+ coverage)
- **OTEL validation is ultimate truth source** - verify with real spans/metrics
- Never trust claims without test/OTEL verification
- **Test behaviors, not implementation details** - Focus on what code does, not how
- Use AAA pattern (Arrange, Act, Assert) for clarity
- Use descriptive test names that explain what is being tested
- Prefer real collaborators over mocks when possible

## Guard Constraints

- max_run_len ≤ 8 (Chatman Constant)
- max_batch_size validation
- Schema validation (IRI format checking)
- Operation validation (H_hot set membership)

## Async/Sync Best Practices

### ❌ NEVER make trait methods async - breaks dyn compatibility
```rust
// ❌ Bad: Async trait methods break dyn compatibility
pub trait ServicePlugin: Send + Sync {
    async fn start(&self) -> Result<ServiceHandle>; // BREAKS dyn ServicePlugin!
}

// ✅ Good: Keep trait methods sync, use async in implementations
pub trait ServicePlugin: Send + Sync {
    fn start(&self) -> Result<ServiceHandle>; // dyn compatible
}
```

### ✅ Use async for I/O and long-running operations
- Use `async` for file operations, network, containers, database queries
- Use `sync` for pure computation and simple operations
- Never block async contexts with `std::thread::sleep` - use `tokio::time::sleep` instead

## Anti-False-Positive Rules - CRITICAL

### ❌ NEVER fake implementation with Ok(()) stubs
```rust
// ❌ Bad: Fake success without doing work
pub fn execute_test(&self) -> Result<()> {
    println!("Test executed successfully");  // LYING!
    Ok(())  // Returns success but did nothing
}

// ✅ Good: Honest about incomplete implementation
pub fn execute_test(&self) -> Result<()> {
    unimplemented!("execute_test: needs container execution, output capture, and result validation")
}

// ✅ Good: Actually implemented
pub fn execute_test(&self) -> Result<()> {
    let container = self.start_container()?;
    let output = container.exec(&self.command)?;
    self.validate_output(&output)?;
    Ok(())  // Now legitimately successful
}
```

### Rules for Production Code
1. If a method body is incomplete, it MUST call `unimplemented!("Feature X: what's missing")`
2. NEVER return `Ok(())` without actually doing the work described by the method name
3. NEVER print "success" when nothing happened
4. CLI commands that don't work MUST throw `unimplemented!()`, not pretend to succeed
5. Methods must either work end-to-end OR throw unimplemented
6. No middle ground - no "partial" implementations that lie about success

## Code Review Checklist

- [ ] All functions have proper error handling
- [ ] All inputs are validated
- [ ] No `unwrap()` or `panic!()` in production paths
- [ ] Real implementations, not placeholders
- [ ] Feature-gated when dependencies are optional
- [ ] Tests cover critical paths
- [ ] Guard constraints enforced (max_run_len ≤ 8)
- [ ] Resources are properly cleaned up
- [ ] No secrets or credentials in code
- [ ] Hot path operations are branchless/constant-time
- [ ] Performance constraints met (≤8 ticks for hot path)
- [ ] Code verified with tests/OTEL validation
- [ ] No fake implementations - incomplete features call `unimplemented!()`
- [ ] All traits are `dyn` compatible (no async trait methods)
- [ ] Tests verify behavior, not implementation details
- [ ] Proper async/sync patterns (async for I/O, sync for computation)

## Definition of Done - Core Team Standards

### Before any code is considered complete, ALL of these must be true:

1. **✅ Compilation**: Code compiles without errors or warnings
2. **✅ No unwrap()/expect()**: Zero usage of unwrap() or expect() in production code
3. **✅ Trait Compatibility**: All traits remain `dyn` compatible (no async trait methods)
4. **✅ Backward Compatibility**: No breaking changes without migration plan
5. **✅ All Tests Pass**: Every test in the codebase passes
6. **✅ No Linting Errors**: Zero linting errors or warnings
7. **✅ Proper Error Handling**: All functions use Result types with meaningful errors
8. **✅ Async/Sync Patterns**: Proper use of async for I/O, sync for computation
9. **✅ No False Positives**: No fake Ok(()) returns from incomplete implementations
10. **✅ Performance Compliance**: Hot path operations ≤8 ticks
11. **✅ OTEL Validation**: Behavior verified with real spans/metrics

### Validation Checklist:
- [ ] `cargo test` passes completely (or `make test-*` for C tests)
- [ ] `cargo clippy` shows no warnings
- [ ] No `unwrap()` or `expect()` in production code
- [ ] All traits are `dyn` compatible
- [ ] No breaking changes to public APIs
- [ ] All error paths use proper Result types
- [ ] Async operations use proper async/await patterns
- [ ] No fake implementations - incomplete features call `unimplemented!()`
- [ ] Tests verify behavior, not implementation details
- [ ] Performance constraints met (≤8 ticks for hot path)

### If ANY of these fail, the code is NOT ready for production.
